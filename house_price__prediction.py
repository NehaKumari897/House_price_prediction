# -*- coding: utf-8 -*-
"""House_Price _prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gUeBLjSRz2DAPD7dEL9w7-IFmMettNWO
"""

from google.colab import drive
drive.mount ('/content/gdrive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from xgboost import XGBRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

# Set style for better visualizations
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (14, 8)

print("=" * 100)
print(" " * 30 + "HOUSE PRICE PREDICTION - ML PROJECT")
print("=" * 100)


# ==================== 1. DATA LOADING ====================
print("\n STEP 1: LOADING DATA")
print("-" * 100)

# Load your CSV file - REPLACE WITH YOUR FILE PATH
df = pd.read_csv('/content/gdrive/MyDrive/gdrive/House_Price_prediction/house_prices.csv')  # ← PUT YOUR CSV FILE NAME HERE

print(f"✓ Data loaded successfully!")
print(f"  Dataset Shape: {df.shape[0]} rows × {df.shape[1]} columns")
print(f"\n  Column Names:")
for i, col in enumerate(df.columns, 1):
    print(f"    {i}. {col}")

print(f"\n  First 5 rows:")
print(df.head())

print(f"\n  Data Types:")
print(df.dtypes)

print(f"\n  Missing Values:")
print(df.isnull().sum())

print(f"\n  Statistical Summary:")
print(df.describe())

# ==================== 2. DATA PREPROCESSING ====================
print("\n\n STEP 2: DATA PREPROCESSING & FEATURE ENGINEERING")
print("-" * 100)

# Handle date column if exists
if 'date' in df.columns:
    df['date'] = pd.to_datetime(df['date'], format='%Y%m%dT%H', errors='coerce')
    df['sale_year'] = df['date'].dt.year
    df['sale_month'] = df['date'].dt.month
    print("✓ Date features extracted (sale_year, sale_month)")

# Calculate house age
current_year = 2025
if 'yr_built' in df.columns:
    df['house_age'] = current_year - df['yr_built']
    print("✓ House age calculated")

# Renovation features
if 'yr_renovated' in df.columns:
    df['is_renovated'] = (df['yr_renovated'] > 0).astype(int)
    df['years_since_renovation'] = np.where(df['yr_renovated'] > 0,
                                             current_year - df['yr_renovated'],
                                             df['house_age'])
    print("✓ Renovation features created")

# Size categories
if 'sqft_living' in df.columns:
    df['size_category'] = pd.cut(df['sqft_living'],
                                  bins=[0, 1000, 2000, 3000, 5000, float('inf')],
                                  labels=['Very Small', 'Small', 'Medium', 'Large', 'Very Large'])
    print("✓ Size category created")

# Bedroom categories
if 'bedrooms' in df.columns:
    df['bedroom_category'] = pd.cut(df['bedrooms'],
                                    bins=[0, 2, 3, 4, 5, float('inf')],
                                    labels=['1-2 BR', '3 BR', '4 BR', '5 BR', '6+ BR'])
    print("✓ Bedroom category created")

# Bathroom categories
if 'bathrooms' in df.columns:
    df['bathroom_category'] = pd.cut(df['bathrooms'],
                                     bins=[0, 1.5, 2.5, 3.5, 4.5, float('inf')],
                                     labels=['1-1.5 Bath', '2-2.5 Bath', '3-3.5 Bath',
                                            '4-4.5 Bath', '5+ Bath'])
    print("✓ Bathroom category created")

# Additional features
if 'sqft_basement' in df.columns:
    df['has_basement'] = (df['sqft_basement'] > 0).astype(int)
    print("✓ Basement indicator created")

if 'sqft_living' in df.columns and 'price' in df.columns:
    df['price_per_sqft'] = df['price'] / df['sqft_living']
    print("✓ Price per sqft calculated")

if 'bedrooms' in df.columns and 'bathrooms' in df.columns:
    df['total_rooms'] = df['bedrooms'] + df['bathrooms']
    print("✓ Total rooms calculated")

if 'sqft_living' in df.columns and 'sqft_lot' in df.columns:
    df['living_lot_ratio'] = df['sqft_living'] / df['sqft_lot']
    print("✓ Living/Lot ratio calculated")

# Location features
if 'lat' in df.columns:
    df['location_cluster'] = pd.qcut(df['lat'], q=3, labels=['South', 'Central', 'North'],
                                     duplicates='drop')
    print("✓ Location cluster created")

# Premium property indicator
if 'waterfront' in df.columns and 'view' in df.columns and 'grade' in df.columns:
    df['is_premium'] = ((df['waterfront'] == 1) | (df['view'] >= 3) | (df['grade'] >= 10)).astype(int)
    print("✓ Premium property indicator created")

print(f"\n  Updated Dataset Shape: {df.shape}")

# ==================== 3. EXPLORATORY DATA ANALYSIS ====================
print("\n\n STEP 3: EXPLORATORY DATA ANALYSIS")
print("-" * 100)

# Create comprehensive visualizations
fig = plt.figure(figsize=(20, 16))
gs = fig.add_gridspec(4, 3, hspace=0.3, wspace=0.3)

# 1. Price Distribution
ax1 = fig.add_subplot(gs[0, 0])
ax1.hist(df['price'], bins=30, color='#3498db', edgecolor='black', alpha=0.7)
ax1.set_title('Price Distribution', fontsize=12, fontweight='bold')
ax1.set_xlabel('Price ($)')
ax1.set_ylabel('Frequency')
ax1.axvline(df['price'].mean(), color='red', linestyle='--', label=f'Mean: ${df["price"].mean():,.0f}')
ax1.legend()

# 2. Price vs Square Footage
ax2 = fig.add_subplot(gs[0, 1])
ax2.scatter(df['sqft_living'], df['price'], alpha=0.5, color='#e74c3c', s=50)
ax2.set_title('Price vs Living Area', fontsize=12, fontweight='bold')
ax2.set_xlabel('Square Footage (sqft)')
ax2.set_ylabel('Price ($)')

# 3. Price vs Bedrooms
ax3 = fig.add_subplot(gs[0, 2])
bedroom_avg = df.groupby('bedrooms')['price'].mean().sort_index()
ax3.bar(bedroom_avg.index, bedroom_avg.values, color='#2ecc71', edgecolor='black')
ax3.set_title('Average Price by Bedrooms', fontsize=12, fontweight='bold')
ax3.set_xlabel('Number of Bedrooms')
ax3.set_ylabel('Average Price ($)')

# 4. Price vs Bathrooms
ax4 = fig.add_subplot(gs[1, 0])
ax4.scatter(df['bathrooms'], df['price'], alpha=0.5, color='#9b59b6', s=50)
ax4.set_title('Price vs Bathrooms', fontsize=12, fontweight='bold')
ax4.set_xlabel('Number of Bathrooms')
ax4.set_ylabel('Price ($)')

# 5. Price vs House Age
ax5 = fig.add_subplot(gs[1, 1])
ax5.scatter(df['house_age'], df['price'], alpha=0.5, color='#f39c12', s=50)
ax5.set_title('Price vs House Age', fontsize=12, fontweight='bold')
ax5.set_xlabel('House Age (years)')
ax5.set_ylabel('Price ($)')

# 6. Price vs Grade
ax6 = fig.add_subplot(gs[1, 2])
grade_avg = df.groupby('grade')['price'].mean().sort_index()
ax6.bar(grade_avg.index, grade_avg.values, color='#e67e22', edgecolor='black')
ax6.set_title('Average Price by Grade', fontsize=12, fontweight='bold')
ax6.set_xlabel('Grade')
ax6.set_ylabel('Average Price ($)')

# 7. Price vs Condition
ax7 = fig.add_subplot(gs[2, 0])
condition_avg = df.groupby('condition')['price'].mean().sort_index()
ax7.bar(condition_avg.index, condition_avg.values, color='#1abc9c', edgecolor='black')
ax7.set_title('Average Price by Condition', fontsize=12, fontweight='bold')
ax7.set_xlabel('Condition')
ax7.set_ylabel('Average Price ($)')

# 8. Price vs Floors
ax8 = fig.add_subplot(gs[2, 1])
floors_avg = df.groupby('floors')['price'].mean().sort_index()
ax8.bar(floors_avg.index, floors_avg.values, color='#f1c40f', edgecolor='black')
ax8.set_title('Average Price by Floors', fontsize=12, fontweight='bold')
ax8.set_xlabel('Number of Floors')
ax8.set_ylabel('Average Price ($)')

# 9. Price per Sqft Distribution
ax9 = fig.add_subplot(gs[2, 2])
ax9.hist(df['price_per_sqft'], bins=30, color='#34495e', edgecolor='black', alpha=0.7)
ax9.set_title('Price per Sqft Distribution', fontsize=12, fontweight='bold')
ax9.set_xlabel('Price per Sqft ($)')
ax9.set_ylabel('Frequency')

# Create a dedicated figure for the correlation heatmap with better sizing
plt.figure(figsize=(14, 12))

# Define numeric columns for correlation
numeric_cols = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',
                'floors', 'view', 'grade', 'sqft_above', 'sqft_basement',
                'house_age', 'total_rooms']

# Filter to only include columns that exist and are numeric
available_cols = [col for col in numeric_cols if col in df.columns and df[col].dtype in ['int64', 'float64', 'int32', 'float32']]

# Check if we have enough columns for correlation
if len(available_cols) >= 2:
    # Calculate correlation matrix
    corr_matrix = df[available_cols].corr()

    # Create heatmap with better formatting
    sns.heatmap(corr_matrix,
                annot=True,           # Show correlation values
                fmt='.2f',            # 2 decimal places
                cmap='coolwarm',      # Color scheme
                center=0,             # Center colormap at 0
                square=True,          # Square cells
                linewidths=0.5,       # Thin grid lines
                linecolor='white',    # White grid lines
                cbar_kws={"shrink": 0.8, "label": "Correlation Coefficient"},
                annot_kws={"size": 9, "weight": "bold"})  # Adjust text size

    plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold', pad=20)
    plt.xticks(rotation=45, ha='right', fontsize=10)
    plt.yticks(rotation=0, fontsize=10)
    plt.tight_layout()

    # Save with high resolution
    plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')
    print("✓ Correlation heatmap saved as 'correlation_heatmap.png'")

    plt.show()
else:
    print(f"Not enough numeric columns found. Available: {available_cols}")

# ==================== 4. PREPARE DATA FOR MODELING ====================
print("\n\n STEP 4: PREPARING DATA FOR MODELING")
print("-" * 100)

# Identify numerical and categorical features from the original df
numerical_features = [
    'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',
    'view', 'grade', 'sqft_above', 'sqft_basement', 'house_age',
    'is_renovated', 'years_since_renovation', 'has_basement',
    'total_rooms', 'living_lot_ratio', 'is_premium', 'lat', 'long'
]
categorical_features = ['waterfront', 'condition'] # These are object types in df

# Filter for columns that actually exist in df
numerical_features = [col for col in numerical_features if col in df.columns]
categorical_features = [col for col in categorical_features if col in df.columns]

X_numerical = df[numerical_features].copy()
X_categorical = df[categorical_features].copy()

# One-Hot Encode categorical features
if not X_categorical.empty:
    X_categorical_encoded = pd.get_dummies(X_categorical, drop_first=True)
    X = pd.concat([X_numerical, X_categorical_encoded], axis=1)
else:
    X = X_numerical.copy()

y = df['price'].copy()

# Handle any missing values in the combined DataFrame X
# At this point, all columns in X should be numeric (original numerical + one-hot encoded)
X = X.fillna(X.mean()) # This will now only operate on numeric columns

# Update feature_columns to reflect the actual columns in X after encoding
feature_columns = list(X.columns)

# Split data: 80% training, 20% testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"✓ Features selected: {len(feature_columns)} features")
print(f"  Features: {', '.join(feature_columns)}")
print(f"\n✓ Data split completed:")
print(f"  Training Set: {X_train.shape[0]} samples ({X_train.shape[0]/len(df)*100:.1f}%)")
print(f"  Testing Set: {X_test.shape[0]} samples ({X_test.shape[0]/len(df)*100:.1f}%)")
print(f"\n✓ Feature scaling completed (StandardScaler)")

# ==================== 5. TRAIN ML MODELS ====================
print("\n\n STEP 5: TRAINING MACHINE LEARNING MODELS")
print("-" * 100)

models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, max_depth=15, n_jobs=-1),
    'XGBoost': XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, max_depth=6, n_jobs=-1),
    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,
                                                    random_state=42, max_depth=5),
    'Neural Network': MLPRegressor(hidden_layer_sizes=(100, 50, 25), max_iter=500,
                                   random_state=42, early_stopping=True, validation_fraction=0.1)
}

results = {}
print("\nTraining models...\n")

for i, (name, model) in enumerate(models.items(), 1):
    print(f"[{i}/{len(models)}] Training {name}...", end=" ")

    # Use scaled data for Linear Regression and Neural Network
    if name in ['Linear Regression', 'Neural Network']:
        model.fit(X_train_scaled, y_train)
        y_pred_train = model.predict(X_train_scaled)
        y_pred_test = model.predict(X_test_scaled)
    else:
        model.fit(X_train, y_train)
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)

    # Calculate metrics
    train_r2 = r2_score(y_train, y_pred_train)
    test_r2 = r2_score(y_test, y_pred_test)
    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
    test_mae = mean_absolute_error(y_test, y_pred_test)

    results[name] = {
        'model': model,
        'train_r2': train_r2,
        'test_r2': test_r2,
        'rmse': test_rmse,
        'mae': test_mae,
        'predictions': y_pred_test
    }

    print(f"✓ Done! (R² = {test_r2:.4f})")

print("\n" + "=" * 100)
print("MODEL EVALUATION RESULTS")
print("=" * 100)

# Create results table
results_df = pd.DataFrame({
    'Model': list(results.keys()),
    'Train R²': [results[m]['train_r2'] for m in results.keys()],
    'Test R²': [results[m]['test_r2'] for m in results.keys()],
    'RMSE': [results[m]['rmse'] for m in results.keys()],
    'MAE': [results[m]['mae'] for m in results.keys()],
    'Accuracy (%)': [results[m]['test_r2'] * 100 for m in results.keys()]
})

results_df = results_df.sort_values('Test R²', ascending=False).reset_index(drop=True)
print("\n" + results_df.to_string(index=False))

best_model_name = results_df.iloc[0]['Model']
best_r2 = results_df.iloc[0]['Test R²']

print("\n" + "=" * 100)
print(f" BEST MODEL: {best_model_name}")
print(f"   Test R² Score: {best_r2:.4f} ({best_r2*100:.2f}% accuracy)")
print(f"   RMSE: ${results_df.iloc[0]['RMSE']:,.2f}")
print(f"   MAE: ${results_df.iloc[0]['MAE']:,.2f}")
print("=" * 100)

# ==================== 6. MODEL COMPARISON VISUALIZATION ====================
print("\n\n STEP 6: VISUALIZING MODEL PERFORMANCE")
print("-" * 100)

# Close previous figures
plt.close('all')

# 1. RMSE Comparison
plt.figure(figsize=(10, 6))
colors_rmse = ['#27ae60' if m == best_model_name else '#3498db' for m in results_df['Model']]
plt.barh(results_df['Model'], results_df['RMSE'], color=colors_rmse, edgecolor='black')
plt.xlabel('RMSE ($)', fontsize=11, fontweight='bold')
plt.title('RMSE Comparison (Lower is Better)', fontsize=12, fontweight='bold')
plt.gca().invert_yaxis()
for i, v in enumerate(results_df['RMSE']):
    plt.text(v, i, f' ${v:,.0f}', va='center', fontsize=9)
plt.tight_layout()
plt.show()

# 2. MAE Comparison
plt.figure(figsize=(10, 6))
colors_mae = ['#27ae60' if m == best_model_name else '#e74c3c' for m in results_df['Model']]
plt.barh(results_df['Model'], results_df['MAE'], color=colors_mae, edgecolor='black')
plt.xlabel('MAE ($)', fontsize=11, fontweight='bold')
plt.title('MAE Comparison (Lower is Better)', fontsize=12, fontweight='bold')
plt.gca().invert_yaxis()
for i, v in enumerate(results_df['MAE']):
    plt.text(v, i, f' ${v:,.0f}', va='center', fontsize=9)
plt.tight_layout()
plt.show()

# 3. R² Score Comparison
plt.figure(figsize=(10, 6))
colors_r2 = ['#27ae60' if m == best_model_name else '#9b59b6' for m in results_df['Model']]
plt.barh(results_df['Model'], results_df['Test R²'], color=colors_r2, edgecolor='black')
plt.xlabel('R² Score', fontsize=11, fontweight='bold')
plt.title('R² Score Comparison (Higher is Better)', fontsize=12, fontweight='bold')
plt.gca().invert_yaxis()
plt.axvline(x=0.8, color='red', linestyle='--', linewidth=2, label='Good Threshold (0.8)')
plt.legend()
for i, v in enumerate(results_df['Test R²']):
    plt.text(v, i, f' {v:.3f}', va='center', fontsize=9)
plt.tight_layout()
plt.show()

# 4. Model Accuracy Comparison
plt.figure(figsize=(10, 6))
colors_acc = ['#27ae60' if m == best_model_name else '#f39c12' for m in results_df['Model']]
plt.bar(range(len(results_df)), results_df['Accuracy (%)'], color=colors_acc, edgecolor='black', width=0.6)
plt.xticks(range(len(results_df)), results_df['Model'], rotation=45, ha='right', fontsize=10)
plt.ylabel('Accuracy (%)', fontsize=11, fontweight='bold')
plt.title('Model Accuracy Comparison', fontsize=12, fontweight='bold')
plt.axhline(y=80, color='red', linestyle='--', linewidth=2, label='80% Threshold')
plt.legend()
plt.grid(axis='y', alpha=0.3)
for i, v in enumerate(results_df['Accuracy (%)']):
    plt.text(i, v + 1, f'{v:.1f}%', ha='center', fontsize=9, fontweight='bold')
plt.tight_layout()
plt.show()

# 5-7. Actual vs Predicted for top 3 models
top_3_models = results_df.head(3)['Model'].tolist()

for model_name in top_3_models:
    plt.figure(figsize=(10, 8))

    y_pred = results[model_name]['predictions']
    r2 = results[model_name]['test_r2']

    plt.scatter(y_test, y_pred, alpha=0.5, s=60, color='#3498db', edgecolors='black', linewidth=0.5)

    # Perfect prediction line
    min_val = min(y_test.min(), y_pred.min())
    max_val = max(y_test.max(), y_pred.max())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')

    plt.xlabel('Actual Price ($)', fontsize=11, fontweight='bold')
    plt.ylabel('Predicted Price ($)', fontsize=11, fontweight='bold')
    plt.title(f'{model_name} - Actual vs Predicted\nR² = {r2:.4f}', fontsize=13, fontweight='bold')
    plt.legend()
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

# 8. Residual Plot for best model
plt.figure(figsize=(10, 6))
best_predictions = results[best_model_name]['predictions']
residuals = y_test - best_predictions
plt.scatter(best_predictions, residuals, alpha=0.5, s=60, color='#e74c3c', edgecolors='black', linewidth=0.5)
plt.axhline(y=0, color='black', linestyle='--', linewidth=2)
plt.xlabel('Predicted Price ($)', fontsize=11, fontweight='bold')
plt.ylabel('Residuals ($)', fontsize=11, fontweight='bold')
plt.title(f'Residual Plot - {best_model_name}', fontsize=13, fontweight='bold')
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

# 9. Error Distribution
plt.figure(figsize=(10, 6))
plt.hist(residuals, bins=30, color='#9b59b6', edgecolor='black', alpha=0.7)
plt.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')
plt.xlabel('Prediction Error ($)', fontsize=11, fontweight='bold')
plt.ylabel('Frequency', fontsize=11, fontweight='bold')
plt.title(f'Error Distribution - {best_model_name}', fontsize=13, fontweight='bold')
plt.legend()
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()

# 10. Feature Importance (Top 15)
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Re-create feature_importance_df as it was defined later
# This assumes 'results' and 'feature_columns' are already defined from previous cells
rf_model = results['Random Forest']['model']
feature_importance_df = pd.DataFrame({
    'Feature': feature_columns,
    'Importance': rf_model.feature_importances_
}).sort_values('Importance', ascending=False).reset_index(drop=True)


plt.figure(figsize=(12, 8))
top_features = feature_importance_df.head(15)
colors_feat = plt.cm.viridis(np.linspace(0, 1, len(top_features)))
plt.barh(top_features['Feature'], top_features['Importance'], color=colors_feat, edgecolor='black')
plt.xlabel('Importance Score', fontsize=11, fontweight='bold')
plt.ylabel('Features', fontsize=11, fontweight='bold')
plt.title(f'Top 15 Feature Importance - {best_model_name}', fontsize=13, fontweight='bold')
plt.gca().invert_yaxis()
for i, v in enumerate(top_features['Importance']):
    plt.text(v, i, f' {v:.4f}', va='center', fontsize=9, fontweight='bold')
plt.tight_layout()
plt.show()

print("\n✓ All visualizations displayed separately!")

# Close previous figures
plt.close('all')

# Create a larger dedicated figure for model comparison
fig = plt.figure(figsize=(12, 7))

# Model Accuracy Comparison with better spacing
colors_acc = ['#27ae60' if m == best_model_name else '#f39c12' for m in results_df['Model']]
bars = plt.bar(range(len(results_df)), results_df['Accuracy (%)'],
               color=colors_acc, edgecolor='black', linewidth=1.5, width=0.6)

# Set x-axis with better formatting
plt.xticks(range(len(results_df)), results_df['Model'],
           rotation=45, ha='right', fontsize=11, fontweight='bold')
plt.yticks(fontsize=11)

# Labels and title
plt.ylabel('Accuracy (%)', fontsize=13, fontweight='bold')
plt.title('Model Accuracy Comparison', fontsize=16, fontweight='bold', pad=20)

# Add threshold line
plt.axhline(y=80, color='red', linestyle='--', linewidth=2.5, label='80% Threshold')
plt.legend(fontsize=11, loc='upper right')

# Grid
plt.grid(axis='y', alpha=0.3, linestyle='--', linewidth=0.7)

# Add value labels on top of bars
for i, v in enumerate(results_df['Accuracy (%)']):
    plt.text(i, v + 1.5, f'{v:.1f}%', ha='center',
             fontsize=11, fontweight='bold', color='black')

# Set y-axis limits to accommodate labels
plt.ylim(0, max(results_df['Accuracy (%)']) + 8)

# Tight layout to prevent label cutoff
plt.tight_layout()

# Save with high resolution
plt.savefig('model_accuracy_comparison.png', dpi=300, bbox_inches='tight')
print("✓ Model accuracy comparison saved as 'model_accuracy_comparison.png'")

plt.show()

# ==================== 7. FEATURE IMPORTANCE ====================
print("\n\n STEP 7: FEATURE IMPORTANCE ANALYSIS")
print("-" * 100)

# Get feature importance from Random Forest (best tree-based model)
rf_model = results['Random Forest']['model']
feature_importance_df = pd.DataFrame({
    'Feature': feature_columns,
    'Importance': rf_model.feature_importances_
}).sort_values('Importance', ascending=False).reset_index(drop=True)

print("\nTop 15 Most Important Features (Random Forest):")
print(feature_importance_df.head(15).to_string(index=False))

# Close previous figures
plt.close('all')

# Visualize feature importance
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))

# Top 15 features
top_15 = feature_importance_df.head(15)
colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(top_15)))
ax1.barh(range(len(top_15)), top_15['Importance'], color=colors, edgecolor='black')
ax1.set_yticks(range(len(top_15)))
ax1.set_yticklabels(top_15['Feature'])
ax1.invert_yaxis()
ax1.set_xlabel('Importance Score', fontsize=12, fontweight='bold')
ax1.set_title('Top 15 Most Important Features', fontsize=14, fontweight='bold')
ax1.grid(axis='x', alpha=0.3)

# Cumulative importance
cumulative_importance = np.cumsum(feature_importance_df['Importance'])
ax2.plot(range(1, len(cumulative_importance) + 1), cumulative_importance,
         marker='o', linewidth=2, markersize=6, color='#e74c3c')
ax2.axhline(y=0.8, color='green', linestyle='--', linewidth=2, label='80% Threshold')
ax2.axhline(y=0.9, color='blue', linestyle='--', linewidth=2, label='90% Threshold')
ax2.set_xlabel('Number of Features', fontsize=12, fontweight='bold')
ax2.set_ylabel('Cumulative Importance', fontsize=12, fontweight='bold')
ax2.set_title('Cumulative Feature Importance', fontsize=14, fontweight='bold')
ax2.legend()
ax2.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('03_feature_importance.png', dpi=300, bbox_inches='tight')
print("\n✓ Feature importance plot saved as '03_feature_importance.png'")

# Force display
plt.draw()
plt.show(block=False)
plt.pause(2)  # Keep figure visible for 2 seconds

# ==================== 8. DISPLAY RESULTS ====================
print("\n\n STEP 8: DISPLAYING RESULTS")
print("-" * 100)

# Display model comparison results
print("\n MODEL COMPARISON RESULTS:")
print("=" * 100)
print(results_df.to_string(index=False))

# Display feature importance
print("\n\n FEATURE IMPORTANCE (Top 15):")
print("=" * 100)
print(feature_importance_df.head(15).to_string(index=False))

# Create predictions dataframe
predictions_df = pd.DataFrame({
    'Actual_Price': y_test.values,
    'Predicted_Price': best_predictions,
    'Error': y_test.values - best_predictions,
    'Absolute_Error': np.abs(y_test.values - best_predictions),
    'Percentage_Error': np.abs((y_test.values - best_predictions) / y_test.values) * 100
})

# Display prediction statistics
print("\n\n PREDICTION STATISTICS:")
print("=" * 100)
print(f"Total Predictions: {len(predictions_df)}")
print(f"Mean Absolute Error: ${predictions_df['Absolute_Error'].mean():,.2f}")
print(f"Median Absolute Error: ${predictions_df['Absolute_Error'].median():,.2f}")
print(f"Mean Percentage Error: {predictions_df['Percentage_Error'].mean():.2f}%")
print(f"Median Percentage Error: {predictions_df['Percentage_Error'].median():.2f}%")

# Display sample predictions
print("\n\n SAMPLE PREDICTIONS (First 10):")
print("=" * 100)
print(predictions_df.head(10).to_string(index=False))

print("\n All results displayed successfully!")

# ==================== PRINT BEST MODEL DETAILS ====================
print("\n\n" + "=" * 100)
print(" " * 30 + " BEST MODEL DETAILS ")
print("=" * 100)

best_model = results[best_model_name]['model']
print(f"\nModel Name: {best_model_name}")
print(f"Model Type: {type(best_model).__name__}")
print("\n" + "-" * 100)
print("PERFORMANCE METRICS:")
print("-" * 100)
print(f"  • Training R² Score:   {results[best_model_name]['train_r2']:.4f}")
print(f"  • Testing R² Score:    {results[best_model_name]['test_r2']:.4f}")
print(f"  • Root Mean Squared Error (RMSE): ${results[best_model_name]['rmse']:,.2f}")
print(f"  • Mean Absolute Error (MAE):      ${results[best_model_name]['mae']:,.2f}")
print(f"  • Accuracy:            {results[best_model_name]['test_r2']*100:.2f}%")

# Model interpretation
if results[best_model_name]['test_r2'] >= 0.9:
    interpretation = "EXCELLENT - Model explains over 90% of price variance"
elif results[best_model_name]['test_r2'] >= 0.8:
    interpretation = "VERY GOOD - Model explains over 80% of price variance"
elif results[best_model_name]['test_r2'] >= 0.7:
    interpretation = "GOOD - Model explains over 70% of price variance"
elif results[best_model_name]['test_r2'] >= 0.6:
    interpretation = "FAIR - Model explains over 60% of price variance"
else:
    interpretation = "NEEDS IMPROVEMENT - Consider more features or different approach"

print(f"\n  • Model Quality: {interpretation}")

# Check for overfitting
train_test_diff = abs(results[best_model_name]['train_r2'] - results[best_model_name]['test_r2'])
if train_test_diff > 0.1:
    print(f"  • Overfitting Warning: Train-Test R² difference is {train_test_diff:.4f} (>0.1)")
    print("    → Model might be overfitting. Consider regularization or more data.")
else:
    print(f"  • Overfitting Check: ✓ Good (Train-Test difference: {train_test_diff:.4f})")

print("\n" + "-" * 100)
print("MODEL PARAMETERS:")
print("-" * 100)
if hasattr(best_model, 'get_params'):
    params = best_model.get_params()
    for key, value in list(params.items())[:10]:  # Show first 10 parameters
        print(f"  • {key}: {value}")
    if len(params) > 10:
        print(f"  ... and {len(params) - 10} more parameters")

print("\n" + "-" * 100)
print("PREDICTION STATISTICS:")
print("-" * 100)
predictions = results[best_model_name]['predictions']
errors = y_test.values - predictions
abs_errors = np.abs(errors)
pct_errors = (abs_errors / y_test.values) * 100

print(f"  • Average Prediction Error:     ${np.mean(abs_errors):,.2f}")
print(f"  • Median Prediction Error:      ${np.median(abs_errors):,.2f}")
print(f"  • Standard Deviation of Error:  ${np.std(errors):,.2f}")
print(f"  • Average Percentage Error:     {np.mean(pct_errors):.2f}%")
print(f"  • Median Percentage Error:      {np.median(pct_errors):.2f}%")
print(f"  • Max Overestimation:           ${np.max(errors):,.2f}")
print(f"  • Max Underestimation:          ${-np.min(errors):,.2f}")

# Predictions within certain error ranges
within_5_pct = np.sum(pct_errors <= 5) / len(pct_errors) * 100
within_10_pct = np.sum(pct_errors <= 10) / len(pct_errors) * 100
within_15_pct = np.sum(pct_errors <= 15) / len(pct_errors) * 100
within_20_pct = np.sum(pct_errors <= 20) / len(pct_errors) * 100

print(f"\n  • Predictions within ±5% error:   {within_5_pct:.1f}%")
print(f"  • Predictions within ±10% error:  {within_10_pct:.1f}%")
print(f"  • Predictions within ±15% error:  {within_15_pct:.1f}%")
print(f"  • Predictions within ±20% error:  {within_20_pct:.1f}%")

print("\n" + "-" * 100)
print("SAMPLE PREDICTIONS:")
print("-" * 100)
sample_predictions = pd.DataFrame({
    'Actual Price': y_test.values[:10],
    'Predicted Price': predictions[:10],
    'Error': errors[:10],
    'Error %': pct_errors[:10]
})
sample_predictions['Actual Price'] = sample_predictions['Actual Price'].apply(lambda x: f"${x:,.0f}")
sample_predictions['Predicted Price'] = sample_predictions['Predicted Price'].apply(lambda x: f"${x:,.0f}")
sample_predictions['Error'] = sample_predictions['Error'].apply(lambda x: f"${x:,.0f}")
sample_predictions['Error %'] = sample_predictions['Error %'].apply(lambda x: f"{x:.2f}%")
print(sample_predictions.to_string(index=True))

print("\n" + "=" * 100)
print(" " * 25 + " USE THIS MODEL FOR HOUSE PRICE PREDICTION! ")
print("=" * 100)

# ==================== TEST ON SAMPLE DATA ====================
print("\n\n" + "=" * 100)
print(" " * 30 + " TESTING MODEL ON SAMPLE DATA ")
print("=" * 100)

print("\nLet's test the best model with some sample house data:")
print("-" * 100)

# Create sample test cases
sample_houses = pd.DataFrame({
    'bedrooms': [3, 4, 2, 5],
    'bathrooms': [2.0, 3.0, 1.5, 4.0],
    'sqft_living': [1800, 2500, 1200, 3500],
    'sqft_lot': [7000, 10000, 5000, 12000],
    'floors': [1, 2, 1, 2],
    'waterfront': [0, 0, 0, 1],
    'view': [0, 2, 0, 4],
    'condition': [3, 4, 3, 5],
    'grade': [7, 8, 6, 10],
    'sqft_above': [1800, 2000, 1200, 2500],
    'sqft_basement': [0, 500, 0, 1000],
    'yr_built': [2000, 1990, 2010, 1995]
})

# Engineer features for sample data
sample_houses['house_age'] = current_year - sample_houses['yr_built']
sample_houses['is_renovated'] = 0
sample_houses['years_since_renovation'] = sample_houses['house_age']
sample_houses['has_basement'] = (sample_houses['sqft_basement'] > 0).astype(int)
sample_houses['total_rooms'] = sample_houses['bedrooms'] + sample_houses['bathrooms']
sample_houses['living_lot_ratio'] = sample_houses['sqft_living'] / sample_houses['sqft_lot']
sample_houses['is_premium'] = ((sample_houses['waterfront'] == 1) |
                                (sample_houses['view'] >= 3) |
                                (sample_houses['grade'] >= 10)).astype(int)

# Add lat/long (using approximate values)
sample_houses['lat'] = [47.5, 47.6, 47.4, 47.7]
sample_houses['long'] = [-122.3, -122.2, -122.4, -122.1]

# Ensure all required features are present
for col in feature_columns:
    if col not in sample_houses.columns:
        sample_houses[col] = 0

# Reorder columns to match training data
sample_houses = sample_houses[feature_columns]

# Make predictions
if best_model_name in ['Linear Regression', 'Neural Network']:
    sample_houses_scaled = scaler.transform(sample_houses)
    sample_predictions = best_model.predict(sample_houses_scaled)
else:
    sample_predictions = best_model.predict(sample_houses)

# Display results
print("\nSample House Predictions:")
print("-" * 100)
for i, pred in enumerate(sample_predictions, 1):
    print(f"\n House {i}:")
    print(f"   Bedrooms: {sample_houses.iloc[i-1]['bedrooms']:.0f} | "
          f"Bathrooms: {sample_houses.iloc[i-1]['bathrooms']:.1f} | "
          f"Sqft: {sample_houses.iloc[i-1]['sqft_living']:.0f} | "
          f"Grade: {sample_houses.iloc[i-1]['grade']:.0f}")
    print(f"    PREDICTED PRICE: ${pred:,.2f}")

print("\n" + "=" * 100)

# ==================== FINAL SUMMARY ====================
print("\n\n" + "=" * 100)
print(" " * 35 + "PROJECT SUMMARY")
print("=" * 100)
print(f"\n✓ Dataset: {len(df):,} houses analyzed")
print(f"✓ Features: {len(feature_columns)} features engineered")
print(f"✓ Models: {len(models)} regression models trained")
print(f"\n BEST MODEL: {best_model_name}")
print(f"   • R² Score: {best_r2:.4f} ({best_r2*100:.2f}% accuracy)")
print(f"   • RMSE: ${results_df.iloc[0]['RMSE']:,.2f}")
print(f"   • MAE: ${results_df.iloc[0]['MAE']:,.2f}")

print(f"\n ALL RESULTS DISPLAYED:")
print("   ✓ Exploratory data analysis visualizations")
print("   ✓ Model comparison metrics")
print("   ✓ Feature importance rankings")
print("   ✓ Prediction accuracy statistics")
print("   ✓ Sample predictions with errors")

print(f"\n KEY INSIGHTS:")
print(f"   • Best performing model achieved {best_r2*100:.2f}% accuracy")
print(f"   • Average prediction error: ${results_df.iloc[0]['MAE']:,.2f}")
print(f"   • Top features: {', '.join(feature_importance_df.head(3)['Feature'].tolist())}")

print("\n" + "=" * 100)
print(" " * 35 + " ANALYSIS COMPLETED! ")

import pickle

print("\n Saving model for deployment...")

# Save the best model
with open('house_price_model.pkl', 'wb') as f:
    pickle.dump(best_model, f)
print(" Model saved!")

# Save the scaler
with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)
print(" Scaler saved!")

# Save feature column names
with open('feature_columns.pkl', 'wb') as f:
    pickle.dump(feature_columns, f)
print(" Feature columns saved!")

print("\n All files saved! Ready for deployment!")